{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7466011,"sourceType":"datasetVersion","datasetId":4345912},{"sourceId":7467651,"sourceType":"datasetVersion","datasetId":4346867}],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\n\n# hyperparameters\nbatch_size = 64\nblock_size = 128\nmax_iters = 10000\neval_interval = 500\nlearning_rate = 3e-4\ndevice = 'cuda:0' if torch.cuda.is_available() else 'cpu'\neval_iters = 200\nn_head = 8\nn_embd = batch_size * n_head\nLAYERS = 6\ndropout = 0.2","metadata":{"_uuid":"23a42c34-2409-4c73-af39-d0cfb81bbd18","_cell_guid":"aab1dba3-a18d-4525-bff8-ac4dd761de93","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-26T17:58:27.599506Z","iopub.execute_input":"2024-01-26T17:58:27.599801Z","iopub.status.idle":"2024-01-26T17:58:30.950794Z","shell.execute_reply.started":"2024-01-26T17:58:27.599776Z","shell.execute_reply":"2024-01-26T17:58:30.949797Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/input/bigram/war_and_peace.txt', 'r', encoding='utf-8') as f:\n    text=f.read()","metadata":{"_uuid":"6d6d76ba-469a-4084-a651-bd079c0b5bab","_cell_guid":"2ff6675c-cb41-4466-b95a-d0e0f173c3c8","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-26T17:58:35.188293Z","iopub.execute_input":"2024-01-26T17:58:35.188778Z","iopub.status.idle":"2024-01-26T17:58:35.287829Z","shell.execute_reply.started":"2024-01-26T17:58:35.188748Z","shell.execute_reply":"2024-01-26T17:58:35.286972Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"len(text)","metadata":{"_uuid":"f73e1288-77b5-449f-8687-66edecf7d426","_cell_guid":"68952c6c-b13f-43b3-ba46-c95cf3c93b05","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-26T17:58:36.540461Z","iopub.execute_input":"2024-01-26T17:58:36.541156Z","iopub.status.idle":"2024-01-26T17:58:36.547458Z","shell.execute_reply.started":"2024-01-26T17:58:36.541126Z","shell.execute_reply":"2024-01-26T17:58:36.546548Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"3198690"},"metadata":{}}]},{"cell_type":"code","source":"chars = sorted(list(set(text)))\nvocab_size = len(chars)\nprint([i for i in chars], vocab_size)","metadata":{"_uuid":"05041ea1-7f0d-4f4a-acd1-c880dedb2343","_cell_guid":"fb00dfd0-4a6e-4190-a515-66a1dcdb84a8","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-26T17:58:37.371393Z","iopub.execute_input":"2024-01-26T17:58:37.372054Z","iopub.status.idle":"2024-01-26T17:58:37.425008Z","shell.execute_reply.started":"2024-01-26T17:58:37.372023Z","shell.execute_reply":"2024-01-26T17:58:37.423872Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"['\\n', ' ', '!', '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'À', 'Á', 'É', 'à', 'á', 'â', 'ä', 'æ', 'ç', 'è', 'é', 'ê', 'ë', 'í', 'î', 'ï', 'ó', 'ô', 'ö', 'ú', 'ü', 'ý', 'œ', '—', '‘', '’', '“', '”'] 104\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### encoding, decoding","metadata":{"_uuid":"077ec836-5f7d-4cd0-9539-4561ba127550","_cell_guid":"376562d1-bd3e-4dc8-b1ef-c2573ad500d8","trusted":true}},{"cell_type":"code","source":"\nstoi = {ch:i for i,ch in enumerate(chars)}\nitos = {i:ch for i,ch in enumerate(chars)}\nencode=lambda s : [stoi[c] for c in s]\ndecode= lambda s : ''.join([itos[i] for i in s])","metadata":{"_uuid":"0561c859-91ff-4c25-bc99-d21b777e104f","_cell_guid":"2ee58b47-d330-417c-b4aa-452d1ccabb91","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-26T17:58:40.008638Z","iopub.execute_input":"2024-01-26T17:58:40.009404Z","iopub.status.idle":"2024-01-26T17:58:40.015055Z","shell.execute_reply.started":"2024-01-26T17:58:40.009371Z","shell.execute_reply":"2024-01-26T17:58:40.013969Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(encode('hello bye'))\nprint(decode(encode('hello bye')))","metadata":{"_uuid":"06870e15-93bb-4d7f-ab88-156182987b03","_cell_guid":"5b4af531-1574-4bfd-8ecc-b33c477c084c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-26T17:58:40.920953Z","iopub.execute_input":"2024-01-26T17:58:40.921421Z","iopub.status.idle":"2024-01-26T17:58:40.927351Z","shell.execute_reply.started":"2024-01-26T17:58:40.921385Z","shell.execute_reply":"2024-01-26T17:58:40.926255Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"[57, 54, 61, 61, 64, 1, 51, 74, 54]\nhello bye\n","output_type":"stream"}]},{"cell_type":"code","source":"data=torch.tensor(encode(text), dtype=torch.long)\nprint(data[:400])\nprint(data.shape)","metadata":{"_uuid":"744fa3ab-c232-4ce4-b952-7661494c6b0b","_cell_guid":"3c91b3b6-60c3-4824-9d1e-73a8bd8af4c5","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-26T17:58:41.634072Z","iopub.execute_input":"2024-01-26T17:58:41.635016Z","iopub.status.idle":"2024-01-26T17:58:42.397473Z","shell.execute_reply.started":"2024-01-26T17:58:41.634974Z","shell.execute_reply":"2024-01-26T17:58:42.396478Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"tensor([ 25,  38,  38,  34,   1,  38,  37,  28,  20,   1,  11,  18,  10,  15,\n          0,  26,  31,  24,  39,  43,  28,  41,   1,  32,   0, 102,  46,  54,\n         61,  61,   6,   1,  39,  67,  58,  63,  52,  54,   6,   1,  68,  64,\n          1,  30,  54,  63,  64,  50,   1,  50,  63,  53,   1,  35,  70,  52,\n         52,  50,   1,  50,  67,  54,   1,  63,  64,  72,   1,  59,  70,  68,\n         69,   1,  55,  50,  62,  58,  61,  74,   1,  54,  68,  69,  50,  69,\n         54,  68,   1,  64,  55,   1,  69,  57,  54,   1,  25,  70,  64,  63,\n         50,  65,  50,  67,  69,  54,  68,   8,   1,  25,  70,  69,   1,  32,\n          1,  72,  50,  67,  63,   1,  74,  64,  70,   6,   1,  58,  55,   1,\n         74,  64,  70,   1,  53,  64,  63, 101,  69,   1,  69,  54,  61,  61,\n          1,  62,  54,   1,  69,  57,  50,  69,   1,  69,  57,  58,  68,   1,\n         62,  54,  50,  63,  68,   1,  72,  50,  67,   6,   1,  58,  55,   1,\n         74,  64,  70,   1,  68,  69,  58,  61,  61,   1,  69,  67,  74,   1,\n         69,  64,   1,  53,  54,  55,  54,  63,  53,   1,  69,  57,  54,   1,\n         58,  63,  55,  50,  62,  58,  54,  68,   1,  50,  63,  53,   1,  57,\n         64,  67,  67,  64,  67,  68,   1,  65,  54,  67,  65,  54,  69,  67,\n         50,  69,  54,  53,   1,  51,  74,   1,  69,  57,  50,  69,   1,  24,\n         63,  69,  58,  52,  57,  67,  58,  68,  69,  99,  32,   1,  67,  54,\n         50,  61,  61,  74,   1,  51,  54,  61,  58,  54,  71,  54,   1,  57,\n         54,   1,  58,  68,   1,  24,  63,  69,  58,  52,  57,  67,  58,  68,\n         69,  99,  32,   1,  72,  58,  61,  61,   1,  57,  50,  71,  54,   1,\n         63,  64,  69,  57,  58,  63,  56,   1,  62,  64,  67,  54,   1,  69,\n         64,   1,  53,  64,   1,  72,  58,  69,  57,   1,  74,  64,  70,   1,\n         50,  63,  53,   1,  74,  64,  70,   1,  50,  67,  54,   1,  63,  64,\n          1,  61,  64,  63,  56,  54,  67,   1,  62,  74,   1,  55,  67,  58,\n         54,  63,  53,   6,   1,  63,  64,   1,  61,  64,  63,  56,  54,  67,\n          1,  62,  74,   1, 100,  55,  50,  58,  69,  57,  55,  70,  61,   1,\n         68,  61,  50,  71,  54,   6, 101,   1,  50,  68,   1,  74,  64,  70,\n          1,  52,  50,  61,  61,   1,  74,  64])\ntorch.Size([3198690])\n","output_type":"stream"}]},{"cell_type":"code","source":"n = int(0.9 * len(data))\n\ntrain_d=data[:n]\nval_d=data[n:]\nlen(train_d), len(val_d)","metadata":{"_uuid":"15a8952d-ef84-4d1b-bcd5-ae478185e916","_cell_guid":"05c87a74-e219-45e4-9e2a-86a8f2cd61dc","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-26T17:58:44.945789Z","iopub.execute_input":"2024-01-26T17:58:44.946482Z","iopub.status.idle":"2024-01-26T17:58:44.953139Z","shell.execute_reply.started":"2024-01-26T17:58:44.946449Z","shell.execute_reply":"2024-01-26T17:58:44.952255Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(2878821, 319869)"},"metadata":{}}]},{"cell_type":"code","source":"# x=train[:block_size]\n# y=train[1:block_size+1]      # offset by 1\n\n# for i in range(block_size):\n    \n#     context=x[:i+1]\n#     target=y[i]\n    \n#     print(f'{context} : {target}')","metadata":{"_uuid":"afccf9a4-055d-47dc-9485-9a687f6eb776","_cell_guid":"585dc18a-82a5-4993-b9f9-9581323042cc","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-26T17:58:46.201796Z","iopub.execute_input":"2024-01-26T17:58:46.202424Z","iopub.status.idle":"2024-01-26T17:58:46.206531Z","shell.execute_reply.started":"2024-01-26T17:58:46.202394Z","shell.execute_reply":"2024-01-26T17:58:46.205433Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"#### Generate batches","metadata":{"_uuid":"e17ea631-a7e2-495e-8e6e-628265a5838c","_cell_guid":"34e87311-f896-4c12-8031-231dfe35739c","trusted":true}},{"cell_type":"code","source":"def gen_batch(split):\n    \n    data=train_d if split=='train' else val_d\n    ix = torch.randint( len(data)-block_size,\n                        (batch_size, ))                     # choose {batch_size} #integers from 0 to data.len - block_s\n    \n    x=torch.stack([data[i: i+block_size] for i in ix])\n    y=torch.stack([data[i+1: i+block_size+1] for i in ix])  \n    xb,yb=x.to(device),y.to(device)\n\n    return xb,yb","metadata":{"_uuid":"c8d05182-a32d-4887-8871-5ef766ab14e4","_cell_guid":"060c531b-7643-48f9-ab5d-0885426fe5fd","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-26T17:58:47.859139Z","iopub.execute_input":"2024-01-26T17:58:47.860033Z","iopub.status.idle":"2024-01-26T17:58:47.866102Z","shell.execute_reply.started":"2024-01-26T17:58:47.860002Z","shell.execute_reply":"2024-01-26T17:58:47.865122Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef estimate_loss():\n    '''\n    Returns a dict of mean train & val split losses.\n    '''\n    out = {}\n    m.eval()\n    for split in ['train', 'val']:\n        losses = torch.zeros(eval_iters)\n        for k in range(eval_iters):\n            X, Y = gen_batch(split)\n            X, Y = X.to(device), Y.to(device)\n            logits, loss = m(X, Y)\n            losses[k] = loss.item()\n        out[split] = losses.mean()\n    m.train()\n    return out","metadata":{"_uuid":"c9335595-834b-4a6e-a7b0-006f84bf6442","_cell_guid":"749a1a76-2609-4e45-8de9-c082afadb69e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-26T17:58:48.280758Z","iopub.execute_input":"2024-01-26T17:58:48.281110Z","iopub.status.idle":"2024-01-26T17:58:48.288279Z","shell.execute_reply.started":"2024-01-26T17:58:48.281081Z","shell.execute_reply":"2024-01-26T17:58:48.287114Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### Model Building","metadata":{"_uuid":"8dffd6f8-f8d4-49ed-b7c4-60df4e33ad4d","_cell_guid":"bd697040-82ed-488e-b06d-dd1924e7dafc","trusted":true}},{"cell_type":"code","source":"class Head (nn.Module) :\n    ''' \n    single head of MHA\n    '''\n    \n    def __init__(self, head_size):\n        super().__init__()\n        self.query = nn.Linear(n_embd, head_size, bias=False)\n        self.key = nn.Linear(n_embd, head_size, bias=False)        \n        self.value = nn.Linear(n_embd, head_size, bias=False)        \n        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))   # dont register as param\n        self.dropout = nn.Dropout(dropout)\n        \n        \n    def forward(self, x):\n        B,T,C = x.shape\n        \n        # attention(q,k,v) = softmax(q.kT/sqrt(d_k))*v\n        \n        k = self.key(x)\n        q = self.query (x)\n        wt = q @ k.transpose(-2, -1) * C ** -0.5\n        \n        wt = wt.masked_fill(self.tril[:T,:T]==0, float('-inf'))\n        wt = F.softmax(wt, dim=-1)\n        wt = self.dropout(wt)\n        \n        v = self.value(x)\n        out = wt @ v\n        return out","metadata":{"_uuid":"65b97a84-645a-4635-83a4-6ef0b895ee01","_cell_guid":"98c87312-82e7-44ea-9432-6adc8911f207","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-26T17:58:49.527350Z","iopub.execute_input":"2024-01-26T17:58:49.527741Z","iopub.status.idle":"2024-01-26T17:58:49.536984Z","shell.execute_reply.started":"2024-01-26T17:58:49.527714Z","shell.execute_reply":"2024-01-26T17:58:49.536077Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class MultiHeadedAttention (nn.Module) :\n    \n    '''\n    multiheaded att. \n    -> calculate Head() for each head.\n    -> linear layer pass.\n    -> concatenate.\n    -> dropout.\n    '''\n    \n    def __init__(self, n_head, head_size):\n        \n        super().__init__()\n        self.heads =nn.ModuleList([Head(head_size) for _ in range(n_head)])\n        self.proj=nn.Linear(n_embd, n_embd)\n        self.dropout=nn.Dropout(dropout)\n        \n    def forward(self,x):\n        \n        out = torch.cat([h(x) for h in self.heads], dim=-1)\n        out = self.dropout(self.proj(out))\n        \n        return out","metadata":{"_uuid":"f0f52345-4666-47f3-a1b1-40feeb719b30","_cell_guid":"c8949ad0-c247-4ae5-9200-136ed8cad0bd","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-26T17:58:50.090288Z","iopub.execute_input":"2024-01-26T17:58:50.091013Z","iopub.status.idle":"2024-01-26T17:58:50.097934Z","shell.execute_reply.started":"2024-01-26T17:58:50.090983Z","shell.execute_reply":"2024-01-26T17:58:50.096959Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class FeedForward (nn.Module) :\n    '''\n    feed forward layer.\n    linear: n_embd --> [] [] [] []\n    relu\n    linear: [] [] [] [] --> n_embd\n    dropout\n    '''\n    def __init__(self, n_embd) :\n        super().__init__()\n        self.net = nn.Sequential(\n            \n            nn.Linear(n_embd, 4*n_embd),\n            nn.ReLU(),\n            nn.Linear(4*n_embd, n_embd),\n            nn.Dropout(dropout),\n        )\n        \n    def forward(self, x):\n        return self.net(x)","metadata":{"_uuid":"69523cec-716d-410c-af0f-70ac70fc1523","_cell_guid":"846837ce-5496-48fd-a1ba-99234075471d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-26T17:58:50.482599Z","iopub.execute_input":"2024-01-26T17:58:50.483285Z","iopub.status.idle":"2024-01-26T17:58:50.489175Z","shell.execute_reply.started":"2024-01-26T17:58:50.483255Z","shell.execute_reply":"2024-01-26T17:58:50.488164Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"class Block (nn.Module) :\n    '''\n    transformer block. \n    X = MHA( LayerNorm (X) ) + FF ( LayerNorm (X) )\n    '''\n    def __init__(self, n_embd, n_head) :\n        super().__init__()\n        head_size = n_embd // n_head\n        self.sa = MultiHeadedAttention(n_head, head_size)\n        self.ff = FeedForward(n_embd)\n        self.ln1 = nn.LayerNorm(n_embd)\n        self.ln2 = nn.LayerNorm(n_embd)\n        \n    def forward(self, x) :\n        x = x + self.sa(self.ln1(x))\n        x = x +  self.ff(self.ln2(x))\n        return x","metadata":{"_uuid":"49c9e956-1659-4a07-a3d2-17be373ef1b0","_cell_guid":"29c413be-777e-44b4-9386-05b3728730ee","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-26T17:58:50.870118Z","iopub.execute_input":"2024-01-26T17:58:50.870912Z","iopub.status.idle":"2024-01-26T17:58:50.877591Z","shell.execute_reply.started":"2024-01-26T17:58:50.870880Z","shell.execute_reply":"2024-01-26T17:58:50.876593Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class BGM(nn.Module) :\n    def __init__(self,vocab_size):\n        '''\n        token_emb_tab : Token Embedding Table with V embeddings of size V.\n        pos_emb_tab : Positional embedding table.\n        blocks : {LAYERS} number of blocks.\n        ln_final : final ln layer\n        lm_head : \n        '''\n        super().__init__()\n        self.token_emb_tab = nn.Embedding(num_embeddings=vocab_size,\n                                          embedding_dim=n_embd)\n        self.pos_emb_tab = nn.Embedding (block_size, n_embd)\n        self.blocks = nn.Sequential ( *[Block(n_embd, n_head=n_head) for _ in range(LAYERS)])\n        self.ln_final = nn.LayerNorm(n_embd)\n        self.lm_head = nn.Linear(n_embd, vocab_size)\n\n    def forward( self, index, targets=None) :\n        '''fpass : squeeze logits, targets then calc celoss'''\n        \n        B,T = index.shape\n        tok_emb=self.token_emb_tab(index)\n        pos_emb=self.pos_emb_tab(torch.arange(T, device=device))\n        x = tok_emb + pos_emb # !!!!\n        x = self.blocks(x)\n        x = self.ln_final(x)\n        \n        logits = self.lm_head(x)\n        \n        \n        if targets==None:\n            loss=None\n        else:\n            b,t,c=logits.shape\n            logits=logits.view(b*t, c)\n            targets=targets.view(b*t)\n            loss=F.cross_entropy(logits,targets)\n            \n        return logits,loss\n    \n    def generate( self, index, max_new_tokens):\n        '''\n            do fpass for index. take last logit. softmax. \n            calc new index by MN sampling. cat to previous index.\n            repeat for max_token length.\n        '''\n        for _ in range(max_new_tokens):\n            \n            # crop idx to the last block_size tokens\n            idx_cropd = index[:, -block_size:]\n            \n            logits, loss = self(idx_cropd) \n            logits = logits [:, -1, :] \n            p=F.softmax(logits, dim=-1)\n            \n            next_i = torch.multinomial(p, num_samples=1)\n            \n            index = torch.cat((index, next_i),dim=1)\n            \n        return index","metadata":{"_uuid":"adf795ca-63a4-4993-805b-29ed86d91979","_cell_guid":"3e56e185-bbe3-4363-b071-cdc648d7b479","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-26T17:58:51.318561Z","iopub.execute_input":"2024-01-26T17:58:51.319174Z","iopub.status.idle":"2024-01-26T17:58:51.331182Z","shell.execute_reply.started":"2024-01-26T17:58:51.319139Z","shell.execute_reply":"2024-01-26T17:58:51.330164Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## HyperParams List","metadata":{"_uuid":"819c3eb0-b90b-47c3-9335-347a911bf63e","_cell_guid":"42b32a81-d82d-4387-81de-a4db91163609","trusted":true}},{"cell_type":"code","source":"m = BGM(vocab_size)\nm = m.to(device)\nprint(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')","metadata":{"_uuid":"5c54dcd5-d497-4b9f-82b0-ec5f7caf963b","_cell_guid":"cdcc2e9c-e338-424d-bd62-fc9636885483","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-26T17:58:53.721043Z","iopub.execute_input":"2024-01-26T17:58:53.721721Z","iopub.status.idle":"2024-01-26T17:58:54.098876Z","shell.execute_reply.started":"2024-01-26T17:58:53.721685Z","shell.execute_reply":"2024-01-26T17:58:54.097901Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"19.078248 M parameters\n","output_type":"stream"}]},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(m.parameters(), lr=learning_rate)","metadata":{"_uuid":"0996c804-b33e-4a67-b73a-df0226566229","_cell_guid":"36e3c257-08d4-489d-bf85-b5e1bc43fee6","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-26T17:59:33.909961Z","iopub.execute_input":"2024-01-26T17:59:33.910342Z","iopub.status.idle":"2024-01-26T17:59:33.917534Z","shell.execute_reply.started":"2024-01-26T17:59:33.910308Z","shell.execute_reply":"2024-01-26T17:59:33.916441Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"for iter in range(max_iters):\n    if iter % eval_interval == 0 or iter == max_iters - 1:\n        losses = estimate_loss()\n        print(f\"Epoch {iter}: Training loss : {losses['train']:.4f}, Validation loss : {losses['val']:.4f}\")\n\n    xb, yb = gen_batch('train')\n    xb, yb = xb.to(device), yb.to(device)\n    \n    logits, loss = m(xb, yb)\n    optimizer.zero_grad(set_to_none=True)\n    loss.backward()\n    optimizer.step()","metadata":{"_uuid":"916d460e-73bc-461a-a8bb-9b98aa1bb9ec","_cell_guid":"457b4359-2d3f-443e-b13d-38bf74c4117e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-26T17:59:35.171617Z","iopub.execute_input":"2024-01-26T17:59:35.172002Z","iopub.status.idle":"2024-01-26T18:44:30.376178Z","shell.execute_reply.started":"2024-01-26T17:59:35.171970Z","shell.execute_reply":"2024-01-26T18:44:30.375384Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Epoch 0: Training loss : 4.8044, Validation loss : 4.8009\nEpoch 500: Training loss : 1.7418, Validation loss : 1.7554\nEpoch 1000: Training loss : 1.4325, Validation loss : 1.4628\nEpoch 1500: Training loss : 1.3059, Validation loss : 1.3563\nEpoch 2000: Training loss : 1.2390, Validation loss : 1.3024\nEpoch 2500: Training loss : 1.1886, Validation loss : 1.2661\nEpoch 3000: Training loss : 1.1545, Validation loss : 1.2382\nEpoch 3500: Training loss : 1.1307, Validation loss : 1.2148\nEpoch 4000: Training loss : 1.1067, Validation loss : 1.1984\nEpoch 4500: Training loss : 1.0849, Validation loss : 1.1914\nEpoch 5000: Training loss : 1.0686, Validation loss : 1.1801\nEpoch 5500: Training loss : 1.0540, Validation loss : 1.1696\nEpoch 6000: Training loss : 1.0394, Validation loss : 1.1627\nEpoch 6500: Training loss : 1.0256, Validation loss : 1.1584\nEpoch 7000: Training loss : 1.0124, Validation loss : 1.1473\nEpoch 7500: Training loss : 1.0044, Validation loss : 1.1543\nEpoch 8000: Training loss : 0.9923, Validation loss : 1.1499\nEpoch 8500: Training loss : 0.9814, Validation loss : 1.1429\nEpoch 9000: Training loss : 0.9705, Validation loss : 1.1382\nEpoch 9500: Training loss : 0.9623, Validation loss : 1.1341\nEpoch 9999: Training loss : 0.9541, Validation loss : 1.1370\n","output_type":"stream"}]},{"cell_type":"code","source":"context = torch.zeros((1,1) , dtype=torch.long, device=device)\nprint(decode(m.generate(context, max_new_tokens=2000)[0].tolist()))","metadata":{"_uuid":"55258155-b73b-4bc0-84d7-6f612402c5e4","_cell_guid":"fd74b2b3-d7f7-4dad-9b53-7ea120af88fc","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-26T18:49:33.027805Z","iopub.execute_input":"2024-01-26T18:49:33.028573Z","iopub.status.idle":"2024-01-26T18:50:18.441670Z","shell.execute_reply.started":"2024-01-26T18:49:33.028539Z","shell.execute_reply":"2024-01-26T18:50:18.440708Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"\n\nHis were all south and his elbow gracious full with unalm, Márya Dmítrievna.\n\nHer husband came in to a white, evide-de-camp. Thus gunples on which tried throughbrehand their power, eccepting in doling boss. He was just easier than the facts was seliong, and smiled eagerly downy with at the Russians that was a spuffortune and a pilg, conjuring consideration which spirits of the soldiers passed by the soldiers in an hurre—curred an arm. From which the latters soldier they were not finishing the campaign and undecided that Rumyántsev was already desirent for a duc’siance to marque. It came to the count would not forget all there but a man with a man in a dangerous world with Cossack. Kutúzov was very pain. From the fight at Poland, said Rostopchín a restless of men over the dressing, lay a glove man with him. Túshin was mentioned in white handkerchief with the some click note and torment but made his eye opening a wit.\n\nOur vodka cannot known it, he wished to Pault! That are only he not taken part if he returned to the army. Having wisdom of that duel was rejoying in a hurry d’esen continuous will deceive the new devil married!), the second interrupt of the are, he stamped part, acquite the brings and addressed, now frowned his weather, the young man always at headquarters to the Koll. One dream to make up a Prince , to come the duty, the burned from under the rubles, which no one wrote that she never was afraid. She did not answer his feelings to fall if them would return to the importance again need or not receive gracitude, how specially wagged the ield. Assents of thy present battle of Puples, the question was being there, when this continued disposition together, was pressing in amount to even for those who fears of complete nement weighed them with head as he had been into Larate Hélène. He sat till a subject. He was a grace old atime green long hardly becomminiscences from all these de and cresting. This was all the truth through the fortified that, weary, barg\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(m.state_dict(), '/kaggle/working/b64_bl128_3e4_h8_l6_do0.2_10k.pth')","metadata":{"_uuid":"319c99af-fe9e-484d-bd79-64b811a2995c","_cell_guid":"5eda5c55-de8c-41fa-80a3-10ca8c8f6a79","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-26T18:51:05.669972Z","iopub.execute_input":"2024-01-26T18:51:05.670686Z","iopub.status.idle":"2024-01-26T18:51:05.852629Z","shell.execute_reply.started":"2024-01-26T18:51:05.670649Z","shell.execute_reply":"2024-01-26T18:51:05.851484Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"0c0776cb-0a5d-490c-8af0-6e31a8f5b268","_cell_guid":"441bdfc6-e14c-4ad6-a882-85789c65fc9e","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}